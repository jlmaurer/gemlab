{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a74141e-245d-4a28-a4ab-022aa125e0c0",
   "metadata": {},
   "source": [
    "# InSAR Processing Using ASF HYP3 on-demand products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64319b4d-3cd0-43f7-8dce-1f5d85f3c257",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d3634-094b-494a-8c2b-fe02908e46fd",
   "metadata": {},
   "source": [
    "The Alaska Satellite Facility (ASF) archives SAR and InSAR data on behalf of NASA. \n",
    "By searching on their [Vertex website](https://search.asf.alaska.edu/#/?maxResults=250), users can access and download the original data, or in some cases can run basic processing. \n",
    "Vertex also allows users to do basic SBAS processing, which produces interferograms that can be downloaded and processed to time-series. \n",
    "This is what we will in this exercise. \n",
    "\n",
    "\n",
    "The ASF User guide can be found [here](https://docs.asf.alaska.edu/vertex/manual/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b93810d-d035-4dc6-bb94-0683382eab9f",
   "metadata": {},
   "source": [
    "See the HYP3 SDK [here](https://hyp3-docs.asf.alaska.edu/using/sdk/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd3c4af-d531-4c90-b0e9-ae2308458122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyp3_sdk in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (7.7.1)\n",
      "Requirement already satisfied: python-dateutil in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from hyp3_sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from hyp3_sdk) (2.32.4)\n",
      "Requirement already satisfied: urllib3 in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from hyp3_sdk) (2.5.0)\n",
      "Requirement already satisfied: tqdm in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from hyp3_sdk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from python-dateutil->hyp3_sdk) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from requests->hyp3_sdk) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from requests->hyp3_sdk) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages (from requests->hyp3_sdk) (2025.6.15)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hyp3_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "553cf9bb-45fb-432a-8b35-8b453482e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netrc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import resample_data\n",
    "from hyp3_sdk import HyP3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba8b92-ba66-4957-9669-d855a067a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "creds = netrc.netrc().authenticators('urs.earthdata.nasa.gov')\n",
    "assert creds is not None\n",
    "username, _, password = creds\n",
    "\n",
    "hyp3 = HyP3(username=username, password=password)\n",
    "del password\n",
    "batch = hyp3.find_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b2c309-1d50-4993-b341-1bbdec4f86ff",
   "metadata": {},
   "source": [
    "Once you have complete jobs you can download the products to your machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b956f210-9ae4-4ac4-8fcb-8295ff616a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deaef444-55cd-4420-a1af-599f87d3a0e4",
   "metadata": {},
   "source": [
    "### WARNING!!!\n",
    "This step will download files from ASF. \n",
    "These files vary in size but are roughly ~0.5 GB each, so 200 will be ~100 GB. \n",
    "Make sure you have adequete space for downloading before starting! \n",
    "The good news is that file downloads don't repeat, so if the code stops for any reason you can restart from where it ended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea4a6a53-3321-4891-b071-ef005c1e63ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your download folder\n",
    "dload_path_name = Path('asf_insar_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ddc19b-69ad-4d33-96c6-e833fdc1582e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.download_files(dload_path_name, create=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd3e4b-343f-4592-b1c1-2f3c5da31a6c",
   "metadata": {},
   "source": [
    "### Steps\n",
    "The first steps are to download and unzip the products in our working directory. In this case, I have already done this step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6ee1d81-b9cb-429f-9b80-4f7d14e5e7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'asf_insar_data'\n",
      "/mnt/g/Garlic/Documents/Code/GitHub/gemlab/software/insar\n"
     ]
    }
   ],
   "source": [
    "%cd {dload_path_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d20e3f4-c9af-4ecb-bcf9-86337ce0b989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mCf_InSAR_and_GNSS_velocities.ipynb\u001b[0m*      \u001b[01;32mmakeTS.py\u001b[0m*\n",
      "\u001b[01;32mconvert_h5_to_kml.py\u001b[0m*                    \u001b[01;32mprocess_data.py\u001b[0m*\n",
      "\u001b[01;32mInSAR_start.ipynb\u001b[0m*                       \u001b[34;42m__pycache__\u001b[0m/\n",
      "\u001b[01;32mInSAR_with_ASF_ondemand_products.ipynb\u001b[0m*  \u001b[34;42mzipped\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2c8fd7d-7f6e-48c5-a2c4-f6ecee375a15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open *.zip, *.zip.zip or *.zip.ZIP.\n",
      "\n",
      "No zipfiles found.\n"
     ]
    }
   ],
   "source": [
    "# Unzip your folders\n",
    "# Depending on your platform this may not work\n",
    "!unzip '*.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4a499d-ddd3-4200-8cf2-6fc6a348dd93",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mCf_InSAR_and_GNSS_velocities.ipynb\u001b[0m*      \u001b[01;32mmakeTS.py\u001b[0m*\n",
      "\u001b[01;32mconvert_h5_to_kml.py\u001b[0m*                    \u001b[01;32mprocess_data.py\u001b[0m*\n",
      "\u001b[01;32mInSAR_start.ipynb\u001b[0m*                       \u001b[34;42m__pycache__\u001b[0m/\n",
      "\u001b[01;32mInSAR_with_ASF_ondemand_products.ipynb\u001b[0m*  \u001b[34;42mzipped\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab8834f-8a35-4bd6-80b8-1a6c6b8b8387",
   "metadata": {},
   "source": [
    "As you can see, we have a number of folders that each contain a set of files, including unwrapped phase, unwrapped displacements, DEM, look vectors, etc. \n",
    "\n",
    "Each folder is named by the two dates that were used to generate that interferogram, so for example `S1AA_20220420T235621_20220514T235622_VVP024_INT80_G_ueF_CF44` is an interferogram for dates 4/20/2022 and 5/14/2024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54db8016-96b1-4386-b494-19d2e94c925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Count the number of interferograms we have downloaded\n",
    "# If this line does not work on your machine feel free to skip\n",
    "%ls -ld */ | wc -l  # this will count folders only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e791e351-3dd1-4df6-88c8-4f95845098ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘zipped’: File exists\n"
     ]
    }
   ],
   "source": [
    "%mkdir zipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94b6724a-9383-4d6f-8e00-6a8384993eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '*.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%mv *.zip zipped/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba9a17d5-905b-4c47-a175-c541e02ea5bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32mCf_InSAR_and_GNSS_velocities.ipynb\u001b[0m*      \u001b[01;32mmakeTS.py\u001b[0m*\n",
      "\u001b[01;32mconvert_h5_to_kml.py\u001b[0m*                    \u001b[01;32mprocess_data.py\u001b[0m*\n",
      "\u001b[01;32mInSAR_start.ipynb\u001b[0m*                       \u001b[34;42m__pycache__\u001b[0m/\n",
      "\u001b[01;32mInSAR_with_ASF_ondemand_products.ipynb\u001b[0m*  \u001b[34;42mzipped\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bacdab94-2c85-4b46-9b36-6e813fa797db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'S1*/*_unw_phase.tif': No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# some QA/QC\n",
    "%ls S1*/*_unw_phase.tif | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3047aa8-82cd-4ad0-a952-bf0c7223db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'S1*/*_corr.tif': No such file or directory\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# this should match the previous\n",
    "%ls S1*/*_corr.tif | wc -l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc418d27-a2e4-4efe-9554-b6ae10df3c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "nan\n",
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/garlic/.conda/envs/RAiDER-13/lib/python3.13/site-packages/numpy/_core/_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# check file sizes\n",
    "unw_paths = list(dload_path_name.glob('S1*/*_unw_phase.tif'))\n",
    "corr_paths = list(dload_path_name.glob('S1*/*corr.tif'))\n",
    "print(len(unw_paths))\n",
    "print(len(corr_paths))\n",
    "\n",
    "all_heights: list[float] = []\n",
    "all_widths: list[float] = []\n",
    "for path in unw_paths:\n",
    "    with rio.open(path) as f:\n",
    "        all_heights.append(f.height)\n",
    "        all_widths.append(f.width)\n",
    "\n",
    "print(np.mean(all_heights))\n",
    "print(np.mean(all_widths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6a8db7f-5a1a-4dca-afa1-f8c5b1238666",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(unw_paths)) == len(unw_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccdd50-75c7-4934-b2dc-e4d4c6e27a77",
   "metadata": {},
   "source": [
    "The next step is to make sure that all the interferograms have the same shape and geographic extent. \n",
    "We will ensure this using a simple code that uses rasterio to re-project all the interferograms to match a reference. \n",
    "For this code, you will need `rasterio` and `numpy` installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95206390-f0c1-4aca-b0a1-6c94ad723ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, f in enumerate(files):\n",
    "#     with rio.open(f) as F:\n",
    "#         plt.plot([k,k], F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8faaeeea-8d25-44e8-bea5-a385580bbf2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# The function to resize the images is called run_resampling\u001b[39;00m\n\u001b[32m      2\u001b[39m shp_file_path = Path(\u001b[33m'\u001b[39m\u001b[33m~/CEF/Projects/SLU/t92f120/asf_insar_data/stl_polygon/stl_polygon.shp\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m shp_file_path.exists()\n\u001b[32m      4\u001b[39m resample_data.main(shapefile_path=shp_file_path)  \u001b[38;5;66;03m# runs on the current directory by default\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# The function to resize the images is called run_resampling\n",
    "shp_file_path = Path('~/CEF/Projects/SLU/t92f120/asf_insar_data/stl_polygon/stl_polygon.shp')\n",
    "assert shp_file_path.exists()\n",
    "resample_data.main(shapefile_path=shp_file_path)  # runs on the current directory by default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070c06e-f88b-4075-9be4-6d3dd038e467",
   "metadata": {},
   "source": [
    "Once the resampling has finished, we can now proceed with time-series analysis as normal!\n",
    "You can refer to the [InSAR lab](https://github.com/jlmaurer/GE6146/blob/master/notebooks/Lab4_InSAR.ipynb) for more details and plotting examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1fc87-5fae-4eb4-bd6a-ef76897dc5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the same functions as for the lab\n",
    "import makeTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b474f0-fc8a-4b82-b413-6dadd3df3edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = Path.cwd()\n",
    "ifg_paths = list(dir.glob('**/*_unw_phase.tif'))\n",
    "coh_paths = list(dir.glob('**/*_corr.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e177026-fbfc-4b20-bc40-e0f53bba0559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I found 771 interferograms\n"
     ]
    }
   ],
   "source": [
    "print(f'I found {len(ifg_paths)} interferograms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0830827-86ad-43dd-b7d7-83c9e805714f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all the data\n",
    "date_pairs, dates = makeTS.get_dates(ifg_paths)\n",
    "year_fracs = np.array([makeTS.get_year_frac(d) for d in dates])\n",
    "g_matrix = makeTS.make_g_matrix(dates, date_pairs)\n",
    "x_size, y_size, data_type, geo_proj, transform, nodata_val, num_bands = makeTS.read_raster(ifg_paths[0])\n",
    "data = makeTS.get_data(ifg_paths, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35d27f1-94cc-4427-900c-911a48ebb56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interferograms are 2841x3557 pixels in size\n"
     ]
    }
   ],
   "source": [
    "print(f'Interferograms are {y_size}x{x_size} pixels in size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1160dc13-a99f-4d49-b085-c57a4aa38ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need to make a plot of one of the dates or the average coherence so you can pick a reference point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2874ab83-855b-438d-b46d-3c812aea7e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# De-referencing\n",
    "data = makeTS.dereference(data, ref_center=[2500, 2000], ref_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2545b2-0ce5-4f3f-b84b-835fbd5d5328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the time-series data cube\n",
    "ts_array = makeTS.make_ts(g_matrix, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba14e5f3-61c1-4580-8d94-4d498966f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to displacement in meters\n",
    "ts_array = makeTS.radians_to_meters(ts_array, lam=0.056)  # wavelength lam is 5.6 cm for Sentinel-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ab9c1f-6338-4b85-99b0-8e4cd80a7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean velocity by fitting a line\n",
    "vel = makeTS.find_mean_vel(ts_array, year_fracs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddb5b4-d3f0-4ee0-a0d9-31fb6b5654e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2841, 3557)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dbbe28-83ea-4bed-bb4b-e2b04ccd6ef3",
   "metadata": {},
   "source": [
    "### Saving Data\n",
    "Want to change this to use NETCDF and xarray, include time-series and coherence time-series in the files, maybe IFGs and coherence ifgs as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95e812c-b7f3-4608-b705-db42eb48d78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept\n",
      "interceptStd\n",
      "residue\n",
      "velocity\n",
      "velocityStd\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "with h5py.File('velocity.h5') as path:\n",
    "    for key in path.keys():\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b11833-0444-47ce-8f7f-57f3ca6bb3d5",
   "metadata": {},
   "source": [
    "## Tropospheric correction using RAiDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfaabbc-a1e0-4100-b265-8e196e637aca",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403271aa-8acf-4f66-83d0-8e557430474a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
